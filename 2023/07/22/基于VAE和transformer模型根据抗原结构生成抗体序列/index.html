<!DOCTYPE html>
<html lang="zh-Hans">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="x5-fullscreen" content="true">
<meta name="full-screen" content="yes">
<meta name="theme-color" content="#317EFB" />
<meta content="width=device-width, initial-scale=1.0, maximum-scale=5.0, user-scalable=0" name="viewport">
<meta name="description" content="构建思路 数据准备：首先，需要从PDB数据库获取抗体-抗原复合物的数据。需要先对数据进行预处理，以便用于训练模型。之后可以将抗体的氨基酸序列用于训练VAE，并将抗原的结构数据用于训练Transformer模型。  训练VAE：VAE是一种生成模型，可以用于学习抗体氨基酸序列的潜在表示。你可以将抗体的氨基酸序列编码为一种潜在表示，然后从这种潜在表示中解码出原始序列。通过优化VAE的参数，使模型学习到">
<meta property="og:type" content="article">
<meta property="og:title" content="基于VAE和transformer模型根据抗原结构生成抗体序列">
<meta property="og:url" content="http://example.com/2023/07/22/%E5%9F%BA%E4%BA%8EVAE%E5%92%8Ctransformer%E6%A8%A1%E5%9E%8B%E6%A0%B9%E6%8D%AE%E6%8A%97%E5%8E%9F%E7%BB%93%E6%9E%84%E7%94%9F%E6%88%90%E6%8A%97%E4%BD%93%E5%BA%8F%E5%88%97/index.html">
<meta property="og:site_name" content="The Cabin of Hamzone">
<meta property="og:description" content="构建思路 数据准备：首先，需要从PDB数据库获取抗体-抗原复合物的数据。需要先对数据进行预处理，以便用于训练模型。之后可以将抗体的氨基酸序列用于训练VAE，并将抗原的结构数据用于训练Transformer模型。  训练VAE：VAE是一种生成模型，可以用于学习抗体氨基酸序列的潜在表示。你可以将抗体的氨基酸序列编码为一种潜在表示，然后从这种潜在表示中解码出原始序列。通过优化VAE的参数，使模型学习到">
<meta property="og:locale">
<meta property="article:published_time" content="2023-07-22T06:46:48.000Z">
<meta property="article:modified_time" content="2023-07-23T08:26:28.396Z">
<meta property="article:author" content="Li Hanzhang">
<meta name="twitter:card" content="summary">

    <meta name="keywords" content="深度学习，transformer">


<title >基于VAE和transformer模型根据抗原结构生成抗体序列</title>

<!-- Favicon -->

    <link href='/Logo.svg?v=2.0.9' rel='icon' type='image/png' sizes='16x16' ></link>


    <link href='/Logo.svg?v=2.0.9' rel='icon' type='image/png' sizes='32x32' ></link>


    <link href='/Logo.svg?v=2.0.9' rel='apple-touch-icon' sizes='180x180' ></link>


    <link href='/site.webmanifest' rel='manifest' ></link>


<!-- Plugin -->




    
<link rel="stylesheet" href="/css/plugins/bootstrap.row.css">

    
<link rel="stylesheet" href="https://npm.elemecdn.com/locomotive-scroll@4.1.4/dist/locomotive-scroll.min.css">

    
<link rel="stylesheet" href="https://npm.elemecdn.com/@fancyapps/ui@4.0/dist/fancybox.css">

    
    




<!-- Icon -->

    
<link rel="stylesheet" href="//at.alicdn.com/t/c/font_4177738_vsqmc23e2y.css">




<!-- Variable -->
<script>window.ASYNC_CONFIG = {"hostname":"example.com","author":"Li Hanzhang","root":"/","typed_text":["Always Learning","Always Coding","Always Improving"],"theme_version":"2.0.9","theme":{"switch":true,"default":"style-light"},"favicon":{"logo":"Logo.svg","icon16":"Logo.svg","icon32":"Logo.svg","appleTouchIcon":"Logo.svg","webmanifest":"/site.webmanifest","visibilitychange":true,"hidden":"failure.ico","showText":"(/≧▽≦/)咦！又好了！","hideText":"(●—●)喔哟，崩溃啦！"},"i18n":{"placeholder":"搜索文章...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）","author":"本文作者：","copyright_link":"本文链接：","copyright_license_title":"版权声明：","copyright_license_content":"本博客所有文章除特别声明外，均默认采用 undefined 许可协议。","copy_success":"复制成功","copy_failure":"复制失败","open_read_mode":"进入阅读模式","exit_read_mode":"退出阅读模式","notice_outdate_message":"距离上次更新已经 undefined 天了, 文章内容可能已经过时。","just":"刚刚","min":"分钟前","hour":"小时前","day":"天前","month":"个月前"},"swup":false,"plugin":{"flickr_justified_gallery":"https://npm.elemecdn.com/flickr-justified-gallery@latest/dist/fjGallery.min.js"},"icons":{"sun":"icon-rijian","moon":"icon-yueduye-yejianmoshi","play":"icon-24gf-playCircle","email":"icon-youxiang","next":"icon-jinrushiyan","calendar":"icon-riqi","clock":"icon-shijian","user":"icon-totop","back_top":"fas fa-arrow-up","close":"icon-anniu_guanbi","search":"icon-sousuo","reward":"icon-dashang","user_tag":"fas fa-user-alt","toc_tag":"fas fa-th-list","read":"icon-read","arrows":"icon-shangxiazhankai","double_arrows":"icon-shangxiazhankai","copy":"icon-fuzhi"},"icontype":"font","highlight":{"plugin":"highlighjs","theme":true,"copy":true,"lang":true,"title":"default","height_limit":200},"search":{"enable":true,"type":"local","href":"https://www.google.com/search?q=site:","domain":null,"path":"search.xml"}};</script>
<script id="async-page-config">window.PAGE_CONFIG = {"isPost":true,"isHome":false,"postUpdate":"2023-07-23 16:26:28"};</script>

<!-- Theme mode css -->
<link data-swup-theme rel="stylesheet" href="/css/index.css?v=2.0.9" id="trm-switch-style">
<script>
    let defaultMode = ASYNC_CONFIG.theme.default !=='auto' ?  ASYNC_CONFIG.theme.default : (window.matchMedia("(prefers-color-scheme: light)").matches ? 'style-light' : 'style-dark')
    let catchMode = localStorage.getItem('theme-mode') || defaultMode;
    let type = catchMode === 'style-dark' ? 'add' : 'remove';
    document.documentElement.classList[type]('dark')
</script>

<!-- CDN -->


    
    



<!-- Site Analytics -->
 
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="The Cabin of Hamzone" type="application/atom+xml">
</head>

<body>

  <!-- app wrapper -->
  <div class="trm-app-frame">

    <!-- page preloader -->
    <div class="trm-preloader">
    <div class="trm-holder">
        <div class="preloader">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
</div>
    <!-- page preloader end -->

    <!-- change mode preloader -->
    <div class="trm-mode-swich-animation-frame">
    <div class="trm-mode-swich-animation">
        <i class="i-sun"><i class="iconfont icon-rijian"></i></i>
        <div class="trm-horizon"></div>
        <i class="i-moon"><i class="iconfont icon-yueduye-yejianmoshi"></i></i>
    </div>
</div>
    <!-- change mode preloader end -->

      <!-- scroll container -->
      <div id="trm-dynamic-content" class="trm-swup-animation">
        <div id="trm-scroll-container" class="trm-scroll-container" data-scroll-container style="opacity: 0">
          <div data-scroll-section id="content" class="trm-scroll-section">

            <div class="locomotive-scroll__sticky-target" style="position: absolute; top: 0; left: 0; right: 0; bottom: 0; pointer-events: none;"></div>

            <!-- top bar -->
            <header class="trm-top-bar" data-scroll data-scroll-sticky data-scroll-target=".locomotive-scroll__sticky-target" data-scroll-offset="-10">
	<div class="container">
		<div class="trm-left-side">
			<!-- logo -->
<a href="/" class="trm-logo-frame trm-anima-link">
    
        <img alt="logo" src="/Logo.svg">
    
    
        <div class="trm-logo-text">
            Hamzone&#39;s<span>Cabin</span>
        </div>
    
</a>
<!-- logo end -->
		</div>
		<div class="trm-right-side">
			<!-- menu -->
<div class="trm-menu">
    <nav>
        <ul>
            
            <li class="menu-item-has-children ">
                <a  href="/" target="">
                    home
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a data-no-swup href="/categories/" target="">
                    categories
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a data-no-swup href="/archives/" target="">
                    archives
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a data-no-swup href="/about/" target="">
                    About
                </a>
                
                <ul>
                    
                    <li>
                        <a  href="/project/" target="">
                            Project
                        </a>
                    </li>
                    
                </ul>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a data-no-swup href="/links/" target="">
                    Links
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a data-no-swup href="/gallary/" target="">
                    Gallary
                </a>
                
            </li>
            
        </ul>
    </nav>
</div>
<!-- menu end -->
			
    <!-- mode switcher place -->
    <div class="trm-mode-switcher-place">
        <div class="trm-mode-switcher">
            <i class="iconfont icon-rijian"></i>
            <input class="tgl tgl-light" id="trm-swich" type="checkbox">
            <label class="trm-swich" for="trm-swich"></label>
            <i class="iconfont icon-yueduye-yejianmoshi"></i>
        </div>
    </div>
    <!-- mode switcher place end -->

			
    
    <div id="trm-search-btn" class="trm-search-btn">
        <i class="iconfont icon-sousuo"></i>
    </div>
     

		</div>
		<div class="trm-menu-btn">
			<span></span>
		</div>
	</div>
</header>
            <!-- top bar end -->

            <!-- body -->
            
<div class="trm-content-start">
    <!-- banner -->
    <div class="trm-banner" data-scroll data-scroll-direction="vertical">
    
    <!-- banner cover -->
    <img style="object-position:top;object-fit:cover;" alt="banner" class="trm-banner-cover" data-scroll data-scroll-direction="vertical" data-scroll-speed="-3" src="/img/banner.png">
    <!-- banner cover end -->
    

    <!-- banner content -->
    <div class="trm-banner-content trm-overlay">
        <div class="container" data-scroll data-scroll-direction="vertical" data-scroll-speed="0">
            <div class="row">
                
                <div class="col-lg-4"></div>
                
                <div class="col-lg-8">

                    <!-- banner title -->
                    <div class="trm-banner-text ">
                        <div class="trm-label trm-mb-20">
                            NEWS LETTER
                        </div>
                        <h1 class="trm-mb-30 trm-hsmb-font">
                            基于VAE和transformer模型根据抗原结构生成抗体序列
                        </h1>

                        
                            <ul class="trm-breadcrumbs trm-label">
                                <li>
                                    <a href="/" class="trm-anima-link">Home</a>
                                </li>
                                <li>
                                    <span>
                                        2023
                                    </span
                                ></li>
                            </ul>
                        
                    </div>
                    <!-- banner title end -->

                    <!-- scroll hint -->
                    <a href="#about-triger" data-scroll-to="#about-triger" data-scroll-offset="-130" class="trm-scroll-hint-frame">
                        <div class="trm-scroll-hint"></div>
                        <span class="trm-label">Scroll down</span>
                    </a>
                    <!-- scroll hint end -->

                </div>
            </div>
        </div>
    </div>
    <!-- banner content end -->
</div>
    <!-- banner end -->
    <div class="container">
        <div class="row">
            
                <div id="page-sidebar" class="col-lg-4 hidden-sm">
                    <!-- main card -->
                    

<div class="trm-main-card-frame trm-sidebar">
    <div class="trm-main-card" data-scroll data-scroll-repeat data-scroll-sticky data-scroll-target=".locomotive-scroll__sticky-target" data-scroll-offset="60"> 
    
        <div class="trm-user-tabs" id="sidebar-tabs">
           <div class="trm-tabs-nav trm-mb-40" id="trm-tabs-nav">
                <div data-to="tabs-user" class="trm-tabs-nav-item">
                    <i class="iconfont fas fa-user-alt"></i>
                </div>
                <div data-to="tabs-toc" class="trm-tabs-nav-item active">
                    <i class="iconfont fas fa-th-list"></i>
                </div>
           </div>
            <div name="tabs-user" class="trm-tabs-item">
                <!-- card header -->
<div class="trm-mc-header">
    <div class="trm-avatar-frame trm-mb-20">
        <img alt="Avatar" class="trm-avatar" src="/img/avatar.jpg">
    </div>
    <h5 class="trm-name trm-mb-15">
        Hamzone
    </h5>
    
        <div class="trm-label">
            I`m
            <span class="trm-typed-text">
                <!-- Words for theme.user.typedText -->
            </span>
        </div>
    
</div>
<!-- card header end -->
                <!-- sidebar social -->

<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<div class="trm-social">
    
        <a href="https://github.com/Lhz002" title="github" rel="nofollow" target="_blank">
            <i class="iconfont icon-github-fill"></i>
        </a>
    
        <a href="https://bilibili.com" title="bilibili" rel="nofollow" target="_blank">
            <i class="iconfont icon-bilibili"></i>
        </a>
    
</div>

<!-- sidebar social end -->
                <!-- info -->
<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<ul class="trm-table trm-mb-20">
    
        <li>
            <div class="trm-label">
                Name:
            </div>
            <div class="trm-label trm-label-light">
                Li Hanzhang
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                Location:
            </div>
            <div class="trm-label trm-label-light">
                ZheJiang, China
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                Age:
            </div>
            <div class="trm-label trm-label-light">
                20
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                Email:
            </div>
            <div class="trm-label trm-label-light">
                Lhz1209@outlook.com
            </div>
        </li>
    
</ul>
<!-- info end -->

                
    <div class="trm-divider trm-mb-40 trm-mt-40"></div>
    <!-- action button -->
    <div class="text-center">
        <a href="mailto:Lhz1209@outlook.com" class="trm-btn">
            联系我
            <i class="iconfont icon-youxiang"></i>
        </a>
    </div>
    <!-- action button end -->

            </div>
            <div name="tabs-toc" class="trm-tabs-item active">
                <div class="post-toc">
    <ol class="toc"><li class="toc-item toc-level-1"><a rel="nofollow" class="toc-link" href="#构建思路"  data-scroll-to="#构建思路"><span class="toc-number">1.</span> <span class="toc-text">构建思路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a rel="nofollow" class="toc-link" href="#数据准备"  data-scroll-to="#数据准备"><span class="toc-number">1.1.</span> <span class="toc-text">数据准备</span></a></li><li class="toc-item toc-level-2"><a rel="nofollow" class="toc-link" href="#模型定义和训练"  data-scroll-to="#模型定义和训练"><span class="toc-number">1.2.</span> <span class="toc-text">模型定义和训练</span></a></li></ol></li></ol>
</div>
            </div>
        </div>
    
    </div>
</div>
                    <!-- main card end -->
                </div>
            
            <div id="page-content" class="col-lg-8">
                <div class="trm-content" id="trm-content">
                    <div data-scroll data-scroll-repeat data-scroll-offset="500" id="about-triger"></div>

                    <div id="post-info" class="row hidden-sm">
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont icon-riqi trm-icon"></i><br>
            07/22
        </div>
    </div>
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont icon-shijian trm-icon"></i><br>
            14:46
        </div>
    </div>
    <div class="col-sm-4">
        <div id="post-author" class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont icon-totop trm-icon"></i><br>
            Li Hanzhang
        </div>
    </div>
</div>
<div class="trm-card ">
    <article id="article-container" class="trm-publication">
    <h1 id="构建思路"><a href="#构建思路" class="headerlink" title="构建思路"></a>构建思路</h1><ol>
<li><p><strong>数据准备</strong>：首先，需要从PDB数据库获取抗体-抗原复合物的数据。需要先对数据进行预处理，以便用于训练模型。之后可以将抗体的氨基酸序列用于训练VAE，并将抗原的结构数据用于训练Transformer模型。</p>
</li>
<li><p><strong>训练VAE</strong>：VAE是一种生成模型，可以用于学习抗体氨基酸序列的潜在表示。你可以将抗体的氨基酸序列编码为一种潜在表示，然后从这种潜在表示中解码出原始序列。通过优化VAE的参数，使模型学习到如何生成新的抗体序列。</p>
</li>
<li><p><strong>训练Transformer模型</strong>：Transformer模型是一种序列到序列的模型，可以用于根据抗原的结构数据生成抗体的潜在表示。你可以将抗原的结构数据编码为一个序列，然后使用Transformer模型将这个序列转换为抗体的潜在表示。</p>
</li>
<li><p><strong>联合训练</strong>：一旦VAE和Transformer模型都被单独训练过，就可以开始联合训练这两个模型。可以将Transformer模型的输出（即抗体的潜在表示）用作VAE的输入，然后让VAE生成抗体的氨基酸序列。通过优化这两个模型的参数，使模型学习到如何根据抗原的结构数据生成抗体序列。</p>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>首先，我们需要一个函数来解析PDB文件。PDB文件是一种用于存储蛋白质数据的标准格式，其中包含了蛋白质的氨基酸序列和三维结构信息。然后我们需要创建一个数据集类来加载这些数据。</p>
<p>以下是一个解析PDB文件和创建数据集的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line"><span class="keyword">from</span> torch.nn.functional <span class="keyword">import</span> one_hot</span><br><span class="line"><span class="keyword">from</span> Bio.PDB <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析PDB文件并返回序列和结构信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_pdb_file</span>(<span class="params">file_path</span>):</span><br><span class="line">    parser = PDBParser()</span><br><span class="line">    structure = parser.get_structure(<span class="string">&#x27;X&#x27;</span>, file_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取序列信息</span></span><br><span class="line">    ppb = PPBuilder()</span><br><span class="line">    <span class="keyword">for</span> pp <span class="keyword">in</span> ppb.build_peptides(structure):</span><br><span class="line">        sequence = pp.get_sequence()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取结构信息</span></span><br><span class="line">    atom_list = Selection.unfold_entities(structure, <span class="string">&#x27;A&#x27;</span>)</span><br><span class="line">    <span class="comment"># 此处简化为取每个氨基酸的CA原子的坐标，实际应用中可能需要更详细的结构信息</span></span><br><span class="line">    structure_info = [atom.get_coord() <span class="keyword">for</span> atom <span class="keyword">in</span> atom_list <span class="keyword">if</span> atom.get_name() == <span class="string">&#x27;CA&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sequence, structure_info</span><br><span class="line"><span class="comment"># 创建PyTorch数据集类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PDBDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dir_path, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.dir_path = dir_path</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.file_list = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(dir_path) <span class="keyword">if</span> f.endswith(<span class="string">&#x27;.pdb&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.file_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        file_path = os.path.join(self.dir_path, self.file_list[idx])</span><br><span class="line">        sequence, structure_info = parse_pdb_file(file_path)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将序列和结构信息转换为Tensor</span></span><br><span class="line">        sequence_tensor = torch.tensor([amino_acid_to_index[aa] <span class="keyword">for</span> aa <span class="keyword">in</span> sequence], dtype=torch.long)</span><br><span class="line">        sequence_tensor = one_hot(sequence_tensor, num_classes=<span class="built_in">len</span>(amino_acid_to_index))  <span class="comment"># 对氨基酸进行one-hot编码</span></span><br><span class="line">        structure_tensor = torch.tensor(structure_info, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sequence_tensor, structure_tensor</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">        sequences, structures = <span class="built_in">zip</span>(*batch)</span><br><span class="line">        <span class="comment"># 使用填充来处理长度不同的序列</span></span><br><span class="line">        sequences_padded = pad_sequence([torch.flatten(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> sequences], batch_first=<span class="literal">True</span>, padding_value=<span class="number">0</span>)</span><br><span class="line">        structures_padded = pad_sequence(structures, batch_first=<span class="literal">True</span>, padding_value=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> sequences_padded, structures_padded</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据加载器</span></span><br><span class="line">train_dataset = PDBDataset(<span class="string">&#x27;/path/to/your/pdb/files&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, collate_fn=PDBDataset.collate_fn)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在这段代码中，我们首先定义了一个函数<code>parse_pdb_file</code>来解析PDB文件。然后我们定义了一个PyTorch数据集类<code>PDBDataset</code>，它会遍历给定目录中的所有PDB文件，对每个文件调用<code>parse_pdb_file</code>函数，并将结果转换为Tensor。</p>
<p>由于蛋白质序列的长度可能会不同，我们需要对<code>PDBDataset</code>类进行一些修改，以处理这些长度不同的序列。</p>
<p>一种常用的方法是使用填充（padding），即在较短的序列后面添加一些特殊的元素（例如零），以使所有的序列都有相同的长度。在PyTorch中，我们可以使用<code>torch.nn.utils.rnn.pad_sequence</code>函数来实现这个功能。</p>
<p>我在<code>__getitem__</code>方法中增加了一个one-hot编码的步骤。之后在<code>collate_fn</code>方法中添加了一个填充的步骤，这个步骤会在每个批次中被调用，以处理长度不同的序列。最后，我在创建数据加载器时传入了这个新的<code>collate_fn</code>方法，以覆盖默认的数据组合方法。</p>
<h2 id="模型定义和训练"><a href="#模型定义和训练" class="headerlink" title="模型定义和训练"></a>模型定义和训练</h2><p>由于我们想要的模型是基于抗原结构生成抗体序列的生成模型，我们需要对模型做出一些修改以适应这个任务。我们需要使用抗原的结构信息作为输入，然后使用VAE的解码器部分生成抗体的氨基酸序列。此外，我们还需要在模型中添加一个Transformer层，用于处理输入的抗原结构信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义VAE</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VAE, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">1024</span>, <span class="number">400</span>)</span><br><span class="line">        self.fc21 = nn.Linear(<span class="number">400</span>, <span class="number">20</span>)</span><br><span class="line">        self.fc22 = nn.Linear(<span class="number">400</span>, <span class="number">20</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">20</span>, <span class="number">400</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">400</span>, <span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, x</span>):</span><br><span class="line">        h1 = F.relu(self.fc1(x))</span><br><span class="line">        <span class="keyword">return</span> self.fc21(h1), self.fc22(h1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reparameterize</span>(<span class="params">self, mu, logvar</span>):</span><br><span class="line">        std = torch.exp(<span class="number">0.5</span>*logvar)</span><br><span class="line">        eps = torch.randn_like(std)</span><br><span class="line">        <span class="keyword">return</span> mu + eps*std</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, z</span>):</span><br><span class="line">        h3 = F.relu(self.fc3(z))</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(self.fc4(h3))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu, logvar = self.encode(x.view(-<span class="number">1</span>, <span class="number">1024</span>))</span><br><span class="line">        z = self.reparameterize(mu, logvar)</span><br><span class="line">        <span class="keyword">return</span> self.decode(z), mu, logvar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义Transformer模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TransformerModel, self).__init__()</span><br><span class="line">        self.bert = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        outputs = self.bert(x)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型并设置优化器</span></span><br><span class="line">vae = VAE().to(device)</span><br><span class="line">transformer = TransformerModel().to(device)</span><br><span class="line">optimizer = torch.optim.Adam(<span class="built_in">list</span>(vae.parameters()) + <span class="built_in">list</span>(transformer.parameters()), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch, vae, transformer, optimizer, train_loader, device</span>):</span><br><span class="line">    vae.train()</span><br><span class="line">    transformer.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (sequence, structure) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        sequence = sequence.to(device)</span><br><span class="line">        structure = structure.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用Transformer模型处理结构信息</span></span><br><span class="line">        structure_representation = transformer(structure)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将sequence调整为合适的形状</span></span><br><span class="line">        sequence_reshaped = sequence.view(sequence.shape[<span class="number">0</span>], -<span class="number">1</span>, <span class="built_in">len</span>(amino_acid_to_index))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用VAE生成序列</span></span><br><span class="line">        recon_batch, mu, logvar = vae(structure_representation)</span><br><span class="line">        </span><br><span class="line">        loss = loss_function(recon_batch, sequence_reshaped, mu, logvar)</span><br><span class="line">        loss.backward()</span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;====&gt; Epoch: &#123;&#125; Average loss: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_loss / <span class="built_in">len</span>(train_loader.dataset)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">    train(epoch, vae, transformer, optimizer, train_loader, device)</span><br></pre></td></tr></table></figure>

<p>这个修改后的代码首先定义了一个VAE模型和一个Transformer模型。然后，在训练过程中，我们首先使用Transformer模型处理输入的结构信息，然后将这个处理后的结构信息作为输入传递给VAE，让VAE生成序列。我们使用重构损失和KL散度损失来训练这个模型。</p>
</li>
</ol>

</article>
    
    <div class="trm-reward">
        
            <span class="trm-reward-btn trm-glow" onclick='var qr = document.getElementById("qr"); qr.style.display = (qr.style.display === "none") ? "block" : "none";'>
                <i class="iconfont icon-dashang"></i>
            </span>
        
        <p class="trm-reward-comment">I'm so cute. Please give me money.</p>
        <div id="qr" style="display:none;">
            
                <div style="display:inline-block">
                    <a rel="noopener noreferrer" href='' target='_blank' >
                       <img src="/null" alt="支付宝" loading="lazy">
                    </a>
                    <p>支付宝</p>
                </div>
            
        </div>
    </div>

    

</div>
<div id="post-next-prev" class="row">
    <div class="col-lg-12">
        <!-- title -->
        <h5 class="trm-title-with-divider">
            其他文章
            <span data-number="02"></span>
        </h5>
    </div>
    
        <div class="col-lg-6">
    <div class="trm-blog-card trm-scroll-animation" data-scroll data-scroll-offset="40">
        <a href="/2023/07/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" class="trm-cover-frame trm-anima-link">
            
            
                <img alt="cover" class="no-fancybox" src="/img/block.jpg">
            
        </a>
        
        <div class="trm-card-descr">
            <div class="trm-label trm-category trm-mb-20">
                <a href=" /categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E7%B1%BB/">
                    文献阅读类
                </a>
            </div>
            <h5>
                <a href="/2023/07/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" class="trm-anima-link">
                    文献阅读林一瀚老师组：Modulating gene regulation function by chemically controlled transcription factor clustering
                </a>
            </h5>
            <div class="trm-divider trm-mb-20 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>23/07/23</li>
                <li>13:59</li>
                
                    <li>2.4k</li>
                
                
                    <li>8</li>
                
            </ul>
        </div>
    </div>
</div>
    
    
        <div class="col-lg-6">
    <div class="trm-blog-card trm-scroll-animation" data-scroll data-scroll-offset="40">
        <a href="/2023/07/22/%E9%92%88%E5%AF%B9pdb%E6%96%87%E4%BB%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" class="trm-cover-frame trm-anima-link">
            
            
                <img alt="cover" class="no-fancybox" src="/img/block.jpg">
            
        </a>
        
        <div class="trm-card-descr">
            <div class="trm-label trm-category trm-mb-20">
                <a href=" /categories/%E6%8A%80%E6%9C%AF%E7%B1%BB/">
                    技术类
                </a>
            </div>
            <h5>
                <a href="/2023/07/22/%E9%92%88%E5%AF%B9pdb%E6%96%87%E4%BB%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" class="trm-anima-link">
                    针对pdb文件的数据预处理
                </a>
            </h5>
            <div class="trm-divider trm-mb-20 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>23/07/22</li>
                <li>14:17</li>
                
                    <li>1.4k</li>
                
                
                    <li>5</li>
                
            </ul>
        </div>
    </div>
</div>
    
</div>

    



                    <div class="trm-divider footer-divider"></div>

                    <!-- footer -->
                    <footer class="trm-scroll-animation" data-scroll data-scroll-offset="50">

    

    

    
        <div class="trm-footer-item">
            <span>
                由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v6.3.0
            </span>
            <span class="footer-separator" data-separator=" | "></span>
            <span> 
                主题 - 
                <a rel="noopener" href='https://github.com/MaLuns/hexo-theme-async' target='_blank'>Async</a>
                v2.0.9
            </span>
        </div>
      

     

     
</footer>
 
                    <!-- footer end -->

                </div>
            </div>
        </div>
    </div>
</div>
            <!-- body end -->

            <div class="trm-fixed-container" data-scroll data-scroll-sticky data-scroll-target=".locomotive-scroll__sticky-target" data-scroll-offset="-10">
    
        <div class="trm-fixed-btn" data-title="阅读模式" onclick="asyncFun.switchReadMode()">
            <i class="iconfont icon-read"></i>
        </div>
    
    
        <div class="trm-fixed-btn" data-title="单栏和双栏切换" onclick="asyncFun.switchSingleColumn()">
            <i class="iconfont icon-shangxiazhankai"></i>
        </div>
    
    <div id="trm-back-top" class="trm-fixed-btn" data-title="回到顶部">
        <i class="iconfont fas fa-arrow-up"></i>
    </div>
</div>
          </div>
        </div>
      </div>
      <!-- scroll container end -->

  </div>
  <!-- app wrapper end -->

  
    <div class="trm-search-popup">
        <div class="trm-search-wrapper">
            <div class="form trm-search-form">
                <div class="trm-search-input-icon">
                    <i class="iconfont icon-sousuo"></i>
                </div>
                <input class="trm-search-input" type="text" placeholder="搜索文章...">
                <div class="trm-search-btn-close">
                    <i class="iconfont icon-anniu_guanbi"></i>
                </div>
            </div>
            <div class="trm-search-result-container">
                <div class="trm-search-empty">
                    请输入关键词进行搜索
                </div>
            </div>
            <div class="trm-search-footer">
                <div class="trm-search-stats"></div>
                <ul class="trm-search-commands">
                    <li>
                        <kbd class="command-palette-commands-key">
                            <svg width="15" height="15" aria-label="Escape key" role="img">
                                <g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"
                                    stroke-width="1.2">
                                    <path
                                        d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993 0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016.8634 0 1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5c.032.5663-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864 0 1.6425 1.031 1.5443 2.2492h-2.956">
                                    </path>
                                </g>
                            </svg>
                        </kbd>
                        <span class="command-palette-Label">to close</span>
                    </li>
                </ul>
            </div>
        </div>
    </div>

  <!-- Plugin -->




    
    
<script src="https://npm.elemecdn.com/locomotive-scroll@4.1.4/dist/locomotive-scroll.min.js"></script>

    
<script src="https://npm.elemecdn.com/@fancyapps/ui@4.0/dist/fancybox.umd.js"></script>

    

    
        <script src="/js/plugins/typing.js?v=2.0.9"></script>
    

    
        
<script src="https://npm.elemecdn.com/hexo-generator-searchdb@1.4.0/dist/search.js"></script>

        <script src="/js/plugins/local_search.js?v=2.0.9"></script>
    

    <!-- 数学公式 -->
    

    <!-- 评论插件 -->
    
        

        
    



<!-- CDN -->


    

    

    




    <!-- Service Worker -->
    
    <!-- baidu push -->
    


<script id="async-script" src="/js/main.js?v=2.0.9"></script>

<script src="https://unpkg.com/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://unpkg.com/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>

</html>